# Distributed-web-crawler
A scalable distributed web crawler built with Python and Flask that automatically crawls websites, extracts structured data (URL, title, page size, content, and links), and stores it in CSV format, simulating how modern search engines gather and index web data.
